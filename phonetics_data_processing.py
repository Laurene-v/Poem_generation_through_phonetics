# -*- coding: utf-8 -*-
"""Phonetics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YV03ieoDPj555ScvuM19PKsqN8jb1Iex
"""

#pip install eng-to-ipa

#import tensorflow as tf
#from tensorflow.keras.layers.experimental import preprocessing

import numpy as np
import os
import time

import eng_to_ipa as p 
  
  
test1 = p.convert("example: 'skyfall' is not recognized")

test2 = p.ipa_list("example: 'skyfall' is not recognized")
print(test1, test2)

# remarque: ne prend pas en compte les mots qui ne sont pas dans le dictionnaire anglais ("mots*")

# Enregistrement des données :
#os.chdir("./lyrics_phonetics")
#os.chdir("./poems")

def phonetics(textfile):
  file_phonetics = open(textfile[:-4] + "_phonetics.txt", "w", encoding="utf-8")
  with open(textfile, 'r', encoding="utf-8") as file:
    lines = file.readlines()

  for line in lines:
    file_phonetics.write(p.convert(line)+"\n")
  file_phonetics.close()

  print(lines)

# translate everything in phonetics # attention: long (2h environ)
"""for textfile in os.listdir():
  if textfile[-4:]==".txt" and "phonetics" not in textfile:
    phonetics(textfile)
    print(textfile)
"""
dict_unrecognized = {}

def get_unrecognized(textfile_phonetics, dict_unrecognized):
  """ for each file, extract the words that havent been treated by eng-to-ipa so that they can be manually replaced"""
  nb_unrec_words = 0
  dict_unrecognized_textfile={}
  with open(textfile_phonetics,'r', encoding="utf-8") as f:
    for line in f:
        for word in line.split():
          if word[-1]=="*" and word not in dict_unrecognized:
            #print(word)
            nb_unrec_words+=1
            dict_unrecognized[word]="0"  
            dict_unrecognized_textfile[word]="0"
  print(nb_unrec_words)
  print(dict_unrecognized_textfile)

#replacing some unrecognized words: use fasttext?
def unrec():
    for textfile in os.listdir():
        if textfile[-4:]==".txt" and "phonetics" in textfile:
            get_unrecognized(textfile, dict_unrecognized)
            print(textfile)

        print(len(dict_unrecognized))


def merge_phonetics():
    merged_phonetics = open("merged_phonetics.txt", "w", encoding="utf-8")

    for textfile in os.listdir():
        if textfile[-4:]==".txt" and "phonetics" in textfile:
            with open(textfile, 'r', encoding="utf-8") as file:
                lines = file.readlines()
                for line in lines:
                    merged_phonetics.write(line)
                print(textfile)

    merged_phonetics.close()

def merge():
    merged_lyrics = open("merged_lyrics.txt", "w", encoding="utf-8")

    for textfile in os.listdir():
        if textfile[-4:]==".txt" and "phonetics" not in textfile:
            with open(textfile, 'r', encoding="utf-8") as file:
                lines = file.readlines()
                for line in lines:
                    merged_lyrics.write(line)
                print(textfile)

    merged_lyrics.close()
#merge_phonetics()
#unrec()
#print(dict_unrecognized)

#merge_phonetics()
def merge_poems():
    merged_alex = open("merged_quatrains.txt", "w", encoding="utf-8")

    for textfile in os.listdir():
        if textfile[-4:]==".txt":
            with open(textfile, 'r', encoding="utf-8") as file:
                lines = file.readlines()
                for line in lines:
                    if "©" not in line:
                        merged_alex.write(line)
                merged_alex.write("\n")
                print(textfile)

    merged_alex.close()

#merge_poems()
#phonetics("quatrain/merged_quatrains_cleaned.txt")


import syllables
import pronouncing


def cut_at_ten(line):
    counter=0
    sentence = ""
    word=""
    for word in line.split():
        counter+= syllables.estimate(word)
        sentence=sentence+" "+ word
        #print (counter, word)

        if counter>=10 :
            return(sentence, word)
    return(sentence, word)
            
#print(cut_at_ten("Hey how are you doing little", "no"))

import string
import random
def create_rhymes(textfile):
    generated_rhymes= open("generated_rhymes.txt", "w", encoding="utf-8")
    word=""
    with open(textfile, 'r', encoding="utf-8") as file:
        lines = file.readlines()
        i=0
        for line in lines:
            sentence, word=cut_at_ten(line)
            generated_rhymes.write(sentence)
            i+=1
            if "." in word or "," in word:
                    last_word=last_word[:-1]
            if i%2==1:
                
                last_word = pronouncing.rhymes(word.translate(str.maketrans('', '', string.punctuation)))
                #print(last_word)
                generated_rhymes.write("\n")
            else:
                if last_word!=[]:
                    rhymes_id = list(range(len(last_word)-1))
                    rhymes_id.append(0)
                    print("rhymes : ",rhymes_id, len(last_word))
                    random.shuffle(rhymes_id)
                    rhyme_index = rhymes_id.pop()

                    while p.convert(last_word[rhyme_index])[-1]=="*":
                        if len(rhymes_id)==0:
                            break
                        rhyme_index = rhymes_id.pop()
                        


                    generated_rhymes.write(" "+last_word[rhyme_index])
                generated_rhymes.write("\n")
            if i%4==0:
                generated_rhymes.write("\n")




    print("finished")

    generated_rhymes.close()

#create_rhymes("wikisent2_text.txt")
#phonetics("generated_rhymes.txt")

def delete_unrec(textfile):
    cleaned_data= open("cleaned_data.txt", "w", encoding="utf-8")
    with open(textfile,"r", encoding="utf-8") as f:
        for line in f:
            for word in line.split():
                if "*" not in word:
                    #print(word)
                    cleaned_data.write(word)
            cleaned_data.write("\n")

def create_same_rhyme(textfile):
    same_rhyme= open("same_rhyme_cleaned.txt", "w", encoding="utf-8")
    list_rhymes = list_phonetic_rhymes("on")

    with open(textfile,"r", encoding="utf-8") as f:

        for line in f:
            if len(line)>1:
                same_rhyme.write(line[:-2] + list_rhymes[random.randint(0,len(list_rhymes)-1)] + "\n")
            else:
                same_rhyme.write("\n")
            
    same_rhyme.close()

def create_same_two_rhymes(textfile, rhymeA, rhymeB):
    """ creating rhymes that vary between rhyme A and rhyme B every 4 lines"""

    same_rhyme= open("same_rhyme_cleaned.txt", "w", encoding="utf-8")
    list_rhymes_A = list_phonetic_rhymes(rhymeA)
    list_rhymes_B = list_phonetic_rhymes(rhymeB)
    idx_line = 0

    with open(textfile,"r", encoding="utf-8") as f:
        list_rhymes = list_rhymes_A

        for line in f:
            if idx_line%10 < 5:
                list_rhymes = list_rhymes_A
            else:
                list_rhymes = list_rhymes_B


            if len(line)>1:
                same_rhyme.write(line[:-2] + list_rhymes[random.randint(0,len(list_rhymes)-1)] + "\n")
            else:
                same_rhyme.write("\n")

            idx_line +=1
            
    same_rhyme.close()


def list_phonetic_rhymes(word):
    list_phonetic = []
    for word in pronouncing.rhymes(word):
        phonetic = p.convert(word)
        if "*" not in phonetic:
            list_phonetic.append(phonetic)
    return list_phonetic

#print(len(list_phonetic_rhymes("by")))
#print(list_phonetic_rhymes("by"))
#create_same_rhyme("cleaned_data.txt")
#create_same_two_rhymes("cleaned_data.txt", "by", "on")


from codecarbon import EmissionsTracker

def calculate_emissions(function, textfile):
    
    tracker = EmissionsTracker()
    tracker.start()
    print(function, "starting")

    function(textfile) 
    emissions: float = tracker.stop()
    print(function,textfile, " : ")
    print(f"Emissions: {emissions} kg \n\n")


#calculate_emissions(phonetics, "./lyrics_phonetics/merged_lyrics.txt")
